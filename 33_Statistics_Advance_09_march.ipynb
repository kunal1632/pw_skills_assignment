{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb0c4c9",
   "metadata": {},
   "source": [
    "### Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7ca04a",
   "metadata": {},
   "source": [
    "#### Probability Mass Function (PMF):\n",
    "The PMF is used for discrete random variables. It gives the probability that a random variable takes on a specific value. The PMF is defined as P(X = x), where X is the random variable and x is a specific value of X. The PMF satisfies the properties that P(X = x) is non-negative for all x, and the sum of all probabilities for all possible values of X is equal to 1.\n",
    "\n",
    "Example: Consider a fair six-sided die. The PMF of the die can be defined as P(X = x) = 1/6 for x = 1, 2, 3, 4, 5, 6. This means that each face of the die has an equal probability of 1/6.\n",
    "\n",
    "#### Probability Density Function (PDF):\n",
    "The PDF is used for continuous random variables. It gives the probability density at a specific point in the distribution. The PDF is represented as f(x), where x is a specific value of the random variable. The probability of a continuous random variable falling within a certain interval is calculated by integrating the PDF over that interval.\n",
    "\n",
    "Example: The standard normal distribution has a PDF given by the equation f(x) = (1 / √(2π)) * e^(-x^2/2), where e is the base of the natural logarithm and π is pi. The PDF describes the shape of the distribution and provides the likelihood of observing a particular value or range of values. For example, the PDF can be used to calculate the probability of a random variable falling between two specific values in the standard normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03824ae5",
   "metadata": {},
   "source": [
    "### Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad58bf",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a function that gives the probability that a random variable takes on a value less than or equal to a given value. It provides information about the probability distribution of a random variable and is used for various probability and statistical calculations.\n",
    "\n",
    "The CDF is defined as F(x) = P(X ≤ x), where X is the random variable and x is a specific value. The CDF is non-decreasing, starting from 0 and approaching 1 as x goes to infinity. It represents the cumulative probabilities of the random variable.\n",
    "\n",
    "Example: Let's consider a coin toss experiment. The random variable X represents the number of heads obtained in two tosses. The CDF of X would give the probability of getting a number of heads less than or equal to a given value. For instance, F(0) would be the probability of getting 0 or fewer heads, F(1) would be the probability of getting 1 or fewer heads, and so on.\n",
    "\n",
    "The CDF is used for several purposes:\n",
    "\n",
    "1. Probability calculations: The CDF allows us to calculate the probability of a random variable falling within a specific range of values.\n",
    "2. Quantile calculations: The CDF can be inverted to calculate quantiles, which represent specific values that divide the distribution into equal proportions.\n",
    "3. Statistical inference: The CDF is used in hypothesis testing, confidence interval estimation, and other statistical analyses to assess the likelihood of observing certain values or events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42fe3b",
   "metadata": {},
   "source": [
    "### Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c71dba",
   "metadata": {},
   "source": [
    "1. Height of individuals: The distribution of heights in a population tends to follow a normal distribution. The mean and standard deviation of the normal distribution can represent the average height and the variation around the average, respectively.\n",
    "\n",
    "2. Measurement errors: In many scientific and engineering applications, measurement errors often follow a normal distribution. The mean of the normal distribution can represent the expected measurement value, while the standard deviation represents the precision or accuracy of the measurements.\n",
    "\n",
    "3. IQ scores: IQ scores are often assumed to follow a normal distribution. The mean and standard deviation of the normal distribution can represent the average intelligence level and the spread of intelligence scores in the population.\n",
    "\n",
    "4. Random variables: Many naturally occurring random variables, such as the sum of a large number of independent random variables, tend to follow a normal distribution due to the Central Limit Theorem. This applies to phenomena like the distribution of exam scores, the distribution of errors in scientific experiments, and financial market returns.\n",
    "\n",
    "The parameters of the normal distribution determine the shape of the distribution. The mean, denoted as μ, represents the center of the distribution and determines the location of the peak. The standard deviation, denoted as σ, controls the spread or dispersion of the distribution. A larger standard deviation leads to a wider distribution, while a smaller standard deviation results in a narrower distribution.\n",
    "\n",
    "By manipulating the mean and standard deviation, it is possible to shift and scale the normal distribution, allowing it to fit various data sets. This flexibility makes the normal distribution a versatile and widely used model in statistical analysis and hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df682c",
   "metadata": {},
   "source": [
    "### Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008091e2",
   "metadata": {},
   "source": [
    "1. Central Limit Theorem: The normal distribution plays a crucial role in the Central Limit Theorem, which states that the sum or average of a large number of independent and identically distributed random variables tends to follow a normal distribution. This theorem allows us to make statistical inferences and estimate population parameters based on sample data.\n",
    "\n",
    "2. Data Modeling: Many real-life phenomena exhibit a distribution that closely approximates a normal distribution. By assuming normality, we can effectively model and analyze these phenomena. Examples include the distribution of heights, weights, IQ scores, and errors in scientific measurements.\n",
    "\n",
    "3. Statistical Inference: The normal distribution is extensively used in hypothesis testing and confidence interval estimation. When data follows a normal distribution, it allows us to make precise statements about the population parameters and draw reliable conclusions based on statistical analysis.\n",
    "\n",
    "4. Process Control: In industries and manufacturing processes, the normal distribution is often used to monitor and control product quality. By measuring characteristics of a product and assuming normality, statistical control charts can be employed to detect deviations from the expected behavior and take corrective actions.\n",
    "\n",
    "5. Financial Markets: In finance and economics, the normal distribution is used to model the returns of assets and portfolios. This assumption enables the application of various pricing models, risk assessments, and portfolio optimization techniques.\n",
    "\n",
    "Real-life examples of phenomena that can be modeled by the normal distribution include:\n",
    "\n",
    "- Heights and weights of individuals in a population\n",
    "- IQ scores of a group of people\n",
    "- Errors in scientific measurements\n",
    "- Exam scores in a class\n",
    "- Monthly rainfall levels\n",
    "- Blood pressure readings\n",
    "- Stock market returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00376b3",
   "metadata": {},
   "source": [
    "### Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94139809",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a single binary outcome, such as success or failure, with a fixed probability of success, denoted by 'p'. It is named after the Swiss mathematician Jacob Bernoulli. The distribution has only two possible outcomes: 1 (success) with probability 'p' and 0 (failure) with probability '1 - p'. The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(x) = p^x * (1 - p)^(1 - x)\n",
    "\n",
    "where 'x' represents the outcome (0 or 1).\n",
    "\n",
    "Example: Suppose we are flipping a fair coin, where heads represents success (1) and tails represents failure (0). The probability of getting heads is 0.5, so we can model this situation using a Bernoulli distribution with p = 0.5. Each coin flip follows a Bernoulli distribution.\n",
    "\n",
    "The difference between the Bernoulli distribution and the binomial distribution lies in the number of trials or experiments. The Bernoulli distribution is concerned with a single trial or experiment, whereas the binomial distribution is used when we have a fixed number of independent Bernoulli trials.\n",
    "\n",
    "In the binomial distribution, we perform a series of independent Bernoulli trials, each with the same probability of success 'p'. The binomial distribution models the number of successes ('x') that occur in 'n' trials. The probability mass function (PMF) of the binomial distribution is given by:\n",
    "\n",
    "P(x) = (n choose x) * p^x * (1 - p)^(n - x)\n",
    "\n",
    "where 'n' is the number of trials and 'x' is the number of successes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e2c0e",
   "metadata": {},
   "source": [
    "\n",
    "### Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb37b7",
   "metadata": {},
   "source": [
    "\n",
    "Calculating the Z-score:\n",
    "Z = (60 - 50) / 10 = 1\n",
    "\n",
    "Next, we need to find the probability associated with the Z-score using a standard normal distribution table or a statistical software.\n",
    "\n",
    "The probability that a randomly selected observation will be greater than 60 can be calculated as:\n",
    "\n",
    "P(X > 60) = 1 - P(Z <= 1)\n",
    "\n",
    "By looking up the Z-score of 1 in a standard normal distribution table, we find that the cumulative probability is approximately 0.8413.\n",
    "\n",
    "P(X > 60) = 1 - 0.8413 = 0.1587\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60 is approximately 0.1587, or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7443f",
   "metadata": {},
   "source": [
    "### Q7: Explain uniform Distribution with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198eb083",
   "metadata": {},
   "source": [
    "Uniform distribution is a probability distribution where all values within a given range are equally likely to occur. In other words, it is a distribution in which the probability of any particular value occurring is constant and uniform across the range.\n",
    "\n",
    "An example of a uniform distribution is the roll of a fair six-sided die. In this case, the possible outcomes are the numbers 1, 2, 3, 4, 5, and 6, and each outcome has an equal probability of occurring. The probability of rolling any specific number is 1/6, and this probability remains constant for each roll."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242adf0",
   "metadata": {},
   "source": [
    "### Q8: What is the z score? State the importance of the z score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27e8fdc",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a measure of how many standard deviations an individual data point or observation is from the mean of a distribution. It is calculated by subtracting the mean from the data point and dividing the result by the standard deviation.\n",
    "\n",
    "The formula for calculating the z-score of a data point x in a distribution with mean μ and standard deviation σ is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "The importance of the z-score lies in its usefulness in statistical analysis and hypothesis testing. It allows us to:\n",
    "\n",
    "1. Determine the relative position of an individual data point within a distribution.\n",
    "2. Compare observations from different distributions and determine which values are relatively high or low.\n",
    "3. Calculate probabilities and determine the likelihood of obtaining a certain value or range of values.\n",
    "4. Identify outliers or extreme values in a dataset.\n",
    "5. Make inferences and draw conclusions about the population based on sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f43d09d",
   "metadata": {},
   "source": [
    "### Q9: What is Central Limit Theorem? State the significance of the Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb265c8",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that the sampling distribution of the means of a large number of independent and identically distributed (i.i.d.) random variables will approximate a normal distribution, regardless of the shape of the original population distribution. In simpler terms, it suggests that when we take repeated samples from a population, the distribution of sample means will tend to follow a normal distribution.\n",
    "\n",
    "The significance of the Central Limit Theorem lies in its wide applicability and practical implications. Here are some key points:\n",
    "\n",
    "1. Normality: The CLT allows us to assume a normal distribution for sample means, even if the population distribution is not normal. This assumption enables the use of many statistical techniques and inference procedures that rely on normality.\n",
    "\n",
    "2. Inference: The CLT supports the use of inferential statistics, such as hypothesis testing and confidence intervals. By assuming normality, we can make reliable inferences about population parameters based on sample statistics.\n",
    "\n",
    "3. Sample Size: The CLT provides guidance on sample size determination. It states that as the sample size increases, the distribution of sample means becomes increasingly close to a normal distribution. This allows us to estimate the population mean with greater precision.\n",
    "\n",
    "4. Real-world Applications: The CLT is widely applicable in various fields. It is used in survey sampling, quality control, financial analysis, social sciences, and many other areas where random sampling and statistical analysis are involved.\n",
    "\n",
    "5. Foundation for Other Theorems: The CLT serves as a foundation for other important statistical theorems and concepts, such as the law of large numbers and the t-distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71efe74f",
   "metadata": {},
   "source": [
    "### Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dda082",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) relies on certain assumptions to hold true. These assumptions include:\n",
    "\n",
    "Independence: The observations in the sample or population should be independent of each other. In other words, the values should not be influenced by or related to one another.\n",
    "\n",
    "Sample Size: The sample size should be sufficiently large. While there is no strict rule on the minimum sample size, a general guideline is that the sample size should be at least 30. However, for populations with skewed distributions or outliers, a larger sample size may be needed for the CLT to hold.\n",
    "\n",
    "Finite Variance: The population or sample from which the means are calculated should have a finite variance. This assumption ensures that the sample means are not excessively dispersed.\n",
    "\n",
    "Identically Distributed: The random variables in the population or sample should be identically distributed. This means that they follow the same probability distribution with the same mean and variance.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
