{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae9cdb",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c343e5",
   "metadata": {},
   "source": [
    "The assumptions are as follows:\n",
    "\n",
    "1. Independence: The observations within each group should be independent of each other. In other words, the values in one group should not be related to or influenced by the values in other groups. Violation of independence can lead to biased results. For example, if the observations within a group are correlated, such as repeated measurements on the same individuals, independence is violated.\n",
    "\n",
    "2. Normality: The data within each group should follow a normal distribution. This assumption refers to the distribution of the residuals (the differences between the observed values and the group means). Violation of normality can affect the accuracy of the p-values and confidence intervals. For instance, if the data are heavily skewed or have outliers, normality assumption may be violated.\n",
    "\n",
    "3. Homogeneity of variances: The variability of data within each group should be roughly equal (homoscedasticity). In other words, the spread of the data should be similar across all groups. Violation of homogeneity of variances can lead to incorrect conclusions and affect the validity of the F-test in ANOVA. For example, if the variances are not equal between groups, the F-test may be overly liberal or conservative.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results:\n",
    "\n",
    "1. Outliers: Outliers can significantly affect the assumption of normality. If extreme values exist in the data, the assumption of normally distributed residuals may be violated, leading to incorrect conclusions.\n",
    "\n",
    "2. Non-normality: If the data within each group do not follow a normal distribution, the p-values and confidence intervals obtained from ANOVA may not be accurate. In such cases, non-parametric alternatives or transformations of the data may be considered.\n",
    "\n",
    "3. Unequal variances: If the variability of data within groups is not equal, the F-test used in ANOVA may produce misleading results. The assumption of homogeneity of variances can be checked using statistical tests such as Levene's test or Bartlett's test. If violated, alternative analysis methods, such as Welch's ANOVA or a generalized linear model, can be used.\n",
    "\n",
    "4. Violation of independence: If observations within groups are not independent, such as in clustered or correlated data, the assumption of independence is violated. In such cases, more advanced statistical techniques like mixed-effects models or generalized estimating equations (GEE) may be appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e9606",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e01b78b",
   "metadata": {},
   "source": [
    "The three types of ANOVA are:\n",
    "\n",
    "1. One-Way ANOVA: One-Way ANOVA is used when comparing the means of three or more independent groups or levels of a single categorical variable. It determines if there are any significant differences between the group means. This type of ANOVA is appropriate when you have one independent variable (factor) with three or more levels and you want to test for differences among the group means. For example, you might use One-Way ANOVA to compare the mean scores of students from different schools (where the schools represent the levels of the independent variable) on a test.\n",
    "\n",
    "2. Two-Way ANOVA: Two-Way ANOVA is used when there are two independent variables (factors) and you want to analyze their effects on the dependent variable. It allows you to examine main effects (the effects of each independent variable separately) and interaction effects (the combined effects of the independent variables) on the dependent variable. Two-Way ANOVA is appropriate when you want to study the effects of two factors simultaneously. For example, you might use Two-Way ANOVA to investigate the effects of both gender and age group on exam scores.\n",
    "\n",
    "3. Factorial ANOVA: Factorial ANOVA is an extension of Two-Way ANOVA that allows for the analysis of more than two independent variables (factors) and their interactions. It is used when you have multiple independent variables and want to study their combined effects on the dependent variable. Factorial ANOVA is suitable when you want to investigate the effects of two or more factors on the outcome. For example, you might use Factorial ANOVA to analyze the effects of three factors, such as treatment type, dosage, and duration, on patient recovery time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4645cd",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42011da0",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the decomposition of the total variance observed in the data into different components that can be attributed to specific sources of variation. Understanding this concept is crucial in ANOVA because it allows us to quantify and assess the contributions of different factors or sources of variation to the overall variability in the data.\n",
    "\n",
    "In ANOVA, the total variance is divided into two main components:\n",
    "\n",
    "- Between-group variance (or treatment variance): This component of variance measures the variability among the group means or levels of the independent variable(s). It represents the differences between the groups that are due to the effects of the factors being tested.\n",
    "\n",
    "- Within-group variance (or error variance): This component of variance measures the variability within each group. It represents the random variation or unexplained variability in the data that cannot be attributed to the factors being tested.\n",
    "\n",
    "By partitioning the total variance into these two components, ANOVA allows us to assess whether the between-group variance is significantly larger than the within-group variance. If the between-group variance is much larger than the within-group variance, it suggests that the factors being tested have a significant effect on the dependent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aadcf18",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b480d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 123.73333333333335\n",
      "SSE: 84.13333333333335\n",
      "SSR: 39.599999999999994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data for three groups\n",
    "group1 = [10, 12, 13, 15, 11]\n",
    "group2 = [9, 8, 7, 10, 12]\n",
    "group3 = [16, 14, 13, 15, 17]\n",
    "\n",
    "# Concatenate the data into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate the overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "sst = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "group_means = [np.mean(group) for group in [group1, group2, group3]]\n",
    "sse = np.sum([(mean - overall_mean) ** 2 * len(group) for mean, group in zip(group_means, [group1, group2, group3])])\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c454652",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa4df10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect - Factor1: 32.40000000000002\n",
      "Main effect - Factor2: 8.000000000000036\n",
      "Interaction effect: 1.2325951644078312e-31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data for two independent variables (factors) and a dependent variable\n",
    "data = pd.DataFrame({\n",
    "    'Factor1': [1, 1, 2, 2, 3, 3, 4, 4],\n",
    "    'Factor2': [1, 2, 1, 2, 1, 2, 1, 2],\n",
    "    'DependentVariable': [3, 5, 4, 6, 7, 9, 8, 10]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('DependentVariable ~ Factor1 + Factor2 + Factor1:Factor2', data=data).fit()\n",
    "\n",
    "# Perform the ANOVA analysis\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the main effects\n",
    "main_effect_factor1 = anova_table.loc['Factor1', 'sum_sq']\n",
    "main_effect_factor2 = anova_table.loc['Factor2', 'sum_sq']\n",
    "\n",
    "# Extract the interaction effect\n",
    "interaction_effect = anova_table.loc['Factor1:Factor2', 'sum_sq']\n",
    "\n",
    "print(\"Main effect - Factor1:\", main_effect_factor1)\n",
    "print(\"Main effect - Factor2:\", main_effect_factor2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f675efe",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24360f",
   "metadata": {},
   "source": [
    "Based on this information, we can draw the following conclusions:\n",
    "\n",
    "Rejecting the null hypothesis: The p-value of 0.02 is less than the significance level (often set at 0.05), indicating that the observed differences between the groups are statistically significant. Therefore, we have sufficient evidence to reject the null hypothesis of equal means.\n",
    "\n",
    "Differences between the groups: The significant p-value suggests that there are indeed differences between the groups being compared in the one-way ANOVA. However, it does not provide information about the specific groups that differ or the magnitude of the differences.\n",
    "\n",
    "Further analysis: To determine which specific groups are different, post-hoc tests or pairwise comparisons can be conducted. These tests help identify significant differences between individual groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f769b",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d814532d",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important consideration as missing data can impact the validity and power of the analysis. There are several methods to handle missing data in a repeated measures ANOVA, and the choice of method can have consequences on the results. Here are some common approaches:\n",
    "\n",
    "Complete Case Analysis (Listwise deletion): This method involves excluding any participant with missing data on any variable included in the analysis. Only the cases with complete data are used for the analysis. This approach is straightforward but can lead to a reduction in sample size and potential bias if the missingness is related to the variables under investigation. It assumes that the missingness is completely random (MCAR: Missing Completely at Random).\n",
    "\n",
    "Pairwise Deletion (Available Case Analysis): This approach uses all available data for each pairwise comparison, excluding cases only when necessary for a specific analysis. It retains more data than complete case analysis but may yield different results depending on which cases are included in each analysis. It also assumes that the missingness is missing at random (MAR).\n",
    "\n",
    "Imputation: Imputation methods involve estimating or filling in the missing values. Common imputation techniques include mean imputation (replacing missing values with the mean of the variable), regression imputation (predicting missing values based on other variables), and multiple imputation (generating multiple plausible imputed datasets). Imputation methods can help retain sample size and reduce bias, but they introduce uncertainty and can impact the standard errors and significance tests if the imputation model is misspecified.\n",
    "\n",
    "Maximum Likelihood Estimation (MLE): MLE is a more advanced method that estimates the missing values while simultaneously estimating the model parameters. MLE takes into account the covariance structure of the repeated measures data and provides unbiased estimates if the missingness is missing at random (MAR). MLE methods can be computationally intensive and require assumptions about the missing data mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b779ef",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46472e53",
   "metadata": {},
   "source": [
    "Here are some common post-hoc tests used after ANOVA:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD) test: Tukey's HSD is a widely used post-hoc test that compares all possible pairs of group means. It controls the family-wise error rate, making it suitable when conducting multiple pairwise comparisons. Tukey's HSD is recommended when the sample sizes are equal or approximately equal across groups.\n",
    "\n",
    "2. Bonferroni correction: The Bonferroni correction is a conservative approach that adjusts the significance level for each comparison to maintain an overall desired level of significance. The adjusted p-value is obtained by dividing the desired level of significance by the number of pairwise comparisons. Bonferroni correction is more stringent and appropriate when the number of comparisons is relatively small.\n",
    "\n",
    "3. Scheffe's method: Scheffe's method is a conservative post-hoc test that compares all possible pairwise differences while controlling for the overall Type I error rate. It is robust to unequal sample sizes and can be used when the number of groups or comparisons is large.\n",
    "\n",
    "4. Duncan's multiple range test: Duncan's test is a less conservative post-hoc test that compares all possible pairs of means. It ranks the means and uses the Studentized range statistic to determine significant differences. Duncan's test is suitable when the group sizes are unequal, and it provides a more detailed comparison of means.\n",
    "\n",
    "5. Fisher's Least Significant Difference (LSD) test: Fisher's LSD is a simple post-hoc test that compares pairs of means while controlling the experiment-wise error rate. It is less conservative and more powerful than the Bonferroni correction but assumes equal variances across groups.\n",
    "\n",
    "The choice of post-hoc test depends on various factors such as the research question, sample sizes, assumptions, and desired level of control over Type I error. The specific situation where a post-hoc test might be necessary is when conducting a study with multiple groups (e.g., different treatments, conditions, or populations) and obtaining a significant result in the ANOVA. In such cases, post-hoc tests help identify which group differences are statistically significant and provide a more detailed understanding of the relationships among the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89bcd5f",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e64226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 3.8777861730260677\n",
      "p-value: 0.03308116625532813\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Weight loss data for each diet\n",
    "diet_A = [2, 4, 6, 8, 10, 12 , 14, 16, 18, 20]  # List of weight loss values for Diet A\n",
    "diet_B = [3, 5, 7, 9, 11, 12, 14, 8 , 4, 6]  # List of weight loss values for Diet B\n",
    "diet_C = [1, 3, 5, 7, 9, 4, 2, 6, 10, 8]   # List of weight loss values for Diet C\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f13eac",
   "metadata": {},
   "source": [
    "Interpreting the results:\n",
    "\n",
    "- The F-statistic represents the ratio of between-group variability to within-group variability. A larger F-statistic suggests a greater difference between the group means compared to the variability within the groups.\n",
    "- The p-value indicates the statistical significance of the F-statistic. It represents the probability of observing such extreme F-statistic values if the null hypothesis (no difference between the group means) were true. A smaller p-value indicates stronger evidence against the null hypothesis.\n",
    "\n",
    "To interpret the results:\n",
    "\n",
    "-  so the p value is around 0.033 which is less then 0.05 so we will reject the null hypothesis and there are significant difference in the mean weight loss between three biets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0e209",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9719dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                sum_sq    df         F    PR(>F)\n",
      "C(Software)                  30.675982   2.0  0.664211  0.518834\n",
      "C(Experience)                 6.379579   1.0  0.276267  0.601310\n",
      "C(Software):C(Experience)     3.442842   2.0  0.074546  0.928260\n",
      "Residual                   1246.971215  54.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Generate random completion time data\n",
    "n = 10  # Number of employees\n",
    "software_programs = ['Program A', 'Program B', 'Program C']\n",
    "experience_levels = ['Novice', 'Experienced']\n",
    "\n",
    "# Create empty dataframe to store data\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Generate random completion time data for each combination\n",
    "for program in software_programs:\n",
    "    for experience in experience_levels:\n",
    "        time_data = np.random.normal(loc=30, scale=5, size=n)  # Randomly generated completion time data\n",
    "        df = pd.DataFrame({\n",
    "            'Software': [program] * n,\n",
    "            'Experience': [experience] * n,\n",
    "            'Time': time_data\n",
    "        })\n",
    "        data = pd.concat([data, df], ignore_index=True)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf3a693",
   "metadata": {},
   "source": [
    "Interpreting the results:\n",
    "\n",
    "1. If the p-value for the main effect of Software is less than the chosen significance level (e.g., 0.05), it suggests a significant difference in the average completion time between at least two software programs.\n",
    "2. If the p-value for the main effect of Experience is less than the chosen significance level, it indicates a significant difference in the average completion time between novice and experienced employees.\n",
    "3. If the p-value for the interaction effect between Software and Experience is less than the chosen significance level, it suggests that the effect of software programs on completion time differs depending on the experience level of the employees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b497af",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62dc1400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test:\n",
      "t-statistic: -0.8251\n",
      "p-value: 0.4201\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Generate random test scores for the control and experimental groups\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=10)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=10)\n",
    "\n",
    "# Create a dataframe to store the data\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['Control'] * 10 + ['Experimental'] * 10,\n",
    "    'Test Scores': np.concatenate([control_scores, experimental_scores])\n",
    "})\n",
    "\n",
    "# Perform two-sample t-test\n",
    "control_group = data[data['Group'] == 'Control']['Test Scores']\n",
    "experimental_group = data[data['Group'] == 'Experimental']['Test Scores']\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the t-statistic and p-value\n",
    "print(\"Two-sample t-test:\")\n",
    "print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    posthoc = pairwise_tukeyhsd(data['Test Scores'], data['Group'])\n",
    "    print(\"\\nPost-hoc test (Tukey's HSD):\")\n",
    "    print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896328ca",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f34b5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated measures ANOVA:\n",
      "              Anova\n",
      "=================================\n",
      "    F Value Num DF  Den DF Pr > F\n",
      "---------------------------------\n",
      "Day  1.8162 9.0000 18.0000 0.1344\n",
      "=================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# Generate random daily sales data for Store A, Store B, and Store C\n",
    "n_days = 10\n",
    "store_a_sales = np.random.normal(loc=500, scale=100, size=n_days)\n",
    "store_b_sales = np.random.normal(loc=550, scale=120, size=n_days)\n",
    "store_c_sales = np.random.normal(loc=480, scale=90, size=n_days)\n",
    "\n",
    "# Create a dataframe to store the data\n",
    "data = pd.DataFrame({\n",
    "    'Store': ['A'] * n_days + ['B'] * n_days + ['C'] * n_days,\n",
    "    'Day': list(range(1, n_days + 1)) * 3,\n",
    "    'Sales': np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "})\n",
    "\n",
    "# Convert 'Day' column to numeric\n",
    "data['Day'] = pd.to_numeric(data['Day'])\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(data, 'Sales', 'Store', within=['Day'])\n",
    "results = rm_anova.fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(\"Repeated measures ANOVA:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Extract the F-statistic and p-value\n",
    "f_statistic = results.anova_table['F Value'][0]\n",
    "p_value = results.anova_table['Pr > F'][0]\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    # Create a dictionary to map store names to numeric codes\n",
    "    store_codes = {'A': 1, 'B': 2, 'C': 3}\n",
    "    \n",
    "    # Convert store names to numeric codes for post-hoc test\n",
    "    data['StoreCode'] = data['Store'].map(store_codes)\n",
    "    \n",
    "    # Perform post-hoc test (Tukey's HSD)\n",
    "    posthoc = pairwise_tukeyhsd(data['Sales'], data['StoreCode'])\n",
    "    \n",
    "    # Print the post-hoc test results\n",
    "    print(\"\\nPost-hoc test (Tukey's HSD):\")\n",
    "    print(posthoc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
