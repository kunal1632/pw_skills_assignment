{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c212631",
   "metadata": {},
   "source": [
    "### Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "\n",
    "### Design a pipeline that includes the following steps:\n",
    "\n",
    "- Use an automated feature selection method to identify the important features in the dataset. \n",
    "- Create a numerical pipeline that includes the following stops:\n",
    "- impute the missing values in the numerical columns using the mean of the column values. \n",
    "- Scale the numerical columns using standardisation.\n",
    "- Create a categorical pipeline that includes the following steps:\n",
    "- impute the missing values in the categorical columns using the most frequent value of the column. \n",
    "- One-hot encode the categorical columns.\n",
    "- Combine the numerical and categorical pipelines using a ColumnTransformer.\n",
    "- Use a Random Forest Classifier to build the final model.\n",
    "- Evaluate the accuracy of the model on the test dataset.\n",
    "\n",
    "#### Note: Your solution should include code snippets for each step of the pipeline, and a brief explanation of each step. You should also provide an interpretation of the results and suggest possible improvements for the pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fdb5f1",
   "metadata": {},
   "source": [
    "#### Step 1: Automated Feature Selection\n",
    "#### For automated feature selection, we can use techniques like Recursive Feature Elimination (RFE) or feature importance from tree-based models like Random Forest. Here, let's use the feature importance from Random Forest to select important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "data = pd.read_csv('your_dataset.csv')\n",
    "X = data.drop(columns=['target'])  \n",
    "y = data['target'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': rf_classifier.feature_importances_})\n",
    "important_features = importance_df[importance_df['Importance'] > 0.01]['Feature'].tolist()\n",
    "X_train_selected = X_train[important_features]\n",
    "X_test_selected = X_test[important_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b514804b",
   "metadata": {},
   "source": [
    "#### Step 2: Numerical Pipeline\n",
    "#### In this step, we'll handle missing values and scale the numerical columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')), \n",
    "    ('scaler', StandardScaler())  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb609fd6",
   "metadata": {},
   "source": [
    "#### Step 3: Categorical Pipeline In this step, we'll handle missing values and perform one-hot encoding for categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  \n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')) \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eaa518",
   "metadata": {},
   "source": [
    "#### Step 4: Combine Numerical and Categorical Pipelines Here, we'll use ColumnTransformer to combine the numerical and categorical pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numerical_columns = X_train_selected.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_columns = X_train_selected.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_columns),\n",
    "        ('cat', categorical_pipeline, categorical_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train_selected)\n",
    "X_test_preprocessed = preprocessor.transform(X_test_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4105e8a",
   "metadata": {},
   "source": [
    "#### Step 5: Build the Final Model and Evaluate Now, let's use the preprocessed data to train the Random Forest Classifier and evaluate its accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee961d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_classifier_final = RandomForestClassifier(random_state=42)\n",
    "rf_classifier_final.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "y_pred = rf_classifier_final.predict(X_test_preprocessed)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on the test dataset:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c9602",
   "metadata": {},
   "source": [
    "### Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d4821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Voting Classifier on the test dataset: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "random_forest_clf = RandomForestClassifier()\n",
    "logistic_regression_clf = LogisticRegression()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('rf', random_forest_clf), ('lr', logistic_regression_clf)], voting='hard')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('voting', voting_clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the Voting Classifier on the test dataset:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
